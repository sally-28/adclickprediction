from google.colab import drive 
drive.mount('/content/drive')

import numpy as np                   
import pandas as pd                   
import matplotlib.pyplot as plt       
import seaborn as sns    
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import GaussianNB
from imblearn.over_sampling import SMOTE
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier
from imblearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn import metrics
from wordcloud import WordCloud, STOPWORDS
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix


# Importing dataset and examining it
dataset = pd.read_csv("/content/drive/My Drive/advertising dataset.csv")
pd.set_option('display.max_columns', None) # to make sure you can see all the columns in output window
print(dataset.head())
print(dataset.shape)
print(dataset.info())
print(dataset.describe())
print (dataset.duplicated().sum())
print(dataset.isnull().sum())

numerical_features = ['Daily Time Spent on Site','Age','Area Income','Daily Internt Usuage']
categorial_features = ['AdTopic','City','Gender','Country','Clicked on Ad']


#EXPLORATORY DATA ANALYSIS 

sns.jointplot( x="Age", y= "Daily Time Spent on Site",data = dataset )
sns.pairplot(dataset, hue = "Clicked on Ad")
sns.displot(dataset, x="Age", bins= 4,  )


 #Iterating through the .csv data file 
comment_words = ''
stopwords = set(STOPWORDS)
 
# iterate through the csv file
for val in dataset.AdTopic:
     
    # typecaste each val to string
    val = str(val)
 
    # split the value
    tokens = val.split()
     
    # Converts each token into lowercase
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
     
    comment_words += " ".join(tokens)+" "
 
wordcloud = WordCloud(width = 800, height = 800,
                background_color ='white',
                stopwords = stopwords,
                min_font_size = 10).generate(comment_words)
 
# plot the WordCloud image                      
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)
plt.show()

print(pd.crosstab(index=dataset['Country'],columns='count').sort_values(['count'], ascending=False))

print(dataset.groupby(['Gender','Clicked on Ad'])['Clicked on Ad'].count().unstack())

print(dataset.groupby('Clicked on Ad')['Clicked on Ad', 'Daily Time Spent on Site', 'Age', 'Area Income', 
                            'Daily Internet Usage'].mean())
 
 
# Data Model Implementation

# Dividing dataset into label and feature sets
X = dataset.drop(['AdTopic','City','Country','Timestamp','Clicked on Ad'], axis = 1)
Y = dataset['Clicked on Ad']
print(type(X))
print(type(Y))
print(X.shape)
print(Y.shape)

# Normalizing numerical features so that each feature has mean 0 and variance 1
feature_scaler = StandardScaler()
X_scaled = feature_scaler.fit_transform(X)


# Dividing dataset into training and test sets
X_train, X_test, Y_train, Y_test = train_test_split( X_scaled, Y, test_size = 0.3, random_state = 42)

print(X_train.shape)
print(X_test.shape)

# Plotting Correlation Heatmap
import plotly.graph_objs as go
import plotly.figure_factory as ff

corrs = dataset.corr()
figure = ff.create_annotated_heatmap(
    z=corrs.values,
    x=list(corrs.columns),
    y=list(corrs.index),
    annotation_text=corrs.round(2).values,
    showscale=True)
figure.show()


# Implementing Logistic Regression
model = Pipeline([
        ('balancing', SMOTE(random_state = 101)),
        ('classification', SGDClassifier(loss = 'log', penalty = 'elasticnet', random_state = 1))
    ])
grid_param = {'classification__eta0': [.001,.01,.1,1,10,100], 'classification__max_iter' : [100,500,1000], 'classification__alpha': [.001, .01,.1, 1,10,100], 'classification__l1_ratio': [0,0.3,0.5,0.7,1]}

gd_sr = GridSearchCV(estimator=model, param_grid=grid_param, scoring='accuracy', cv=5)

gd_sr.fit(X_scaled, Y)

best_parameters = gd_sr.best_params_
print(best_parameters)

best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator
print("Logistic Regression: ",best_result)

logreg = LogisticRegression()
logreg.fit(X_train,Y_train)
predictions = logreg.predict(X_test)
conf_mat = metrics.confusion_matrix(Y_test, predictions)
plt.figure(figsize=(8,6))
sns.heatmap(conf_mat,annot=True)
plt.title("Confusion_matrix")
plt.xlabel("Predicted Class")
plt.ylabel("Actual class")
plt.show()
print('Confusion matrix: \n', conf_mat)


# Implementing Naive Bayes Classifier
model = MultinomialNB()
# Running cross-validation
kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1) # 10-fold cross-validation
scores=[]
iteration = 0
smote = SMOTE(random_state = 101)
for train_index, test_index in kf.split(X, Y): # Passing X and not X_scaled because MultinomialNB() does not accept negative values as input. This is alright because NBC is indifferent to feature scaling.
    iteration += 1
    print("Iteration ", iteration)
    X_train, Y_train = X.iloc[train_index], Y[train_index]
    X_test, Y_test = X.iloc[test_index], Y[test_index]
   # X_train,Y_train = smote.fit_resample(X_train,Y_train) 
    model.fit(X_train, Y_train) # Fitting NBC
    Y_pred = model.predict(X_test)
    score = metrics.accuracy_score(Y_test, Y_pred)
    print("Cross-validation accuracy score: ", score)
    scores.append(score) # appending cross-validation accuracy for each iteration
mean_score = np.mean(scores)
print("Naives Bayes:", mean_score)



# Implementing Support Vector Classifier
# Tuning the kernel parameter and implementing cross-validation using Grid Search
model = Pipeline([
        ('balancing', SMOTE(random_state = 101)),
        ('classification', SVC(random_state=1) )
    ])
grid_param = {'classification__kernel': ['linear','poly','rbf','sigmoid'], 'classification__C': [.001,.01,.1,1,10,100]}

gd_sr = GridSearchCV(estimator=model, param_grid=grid_param, scoring='accuracy', cv=5)
gd_sr.fit(X_scaled, Y)

best_parameters = gd_sr.best_params_
print(best_parameters)

best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator
print("SVC: ",best_result)

svc = SVC()
svc.fit(X_train, Y_train)
y_pred = svc.predict(X_test)
conf_mat = metrics.confusion_matrix(Y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(conf_mat,annot=True)
plt.title("Confusion_matrix")
plt.xlabel("Predicted Class")
plt.ylabel("Actual class")
plt.show()
print('Confusion matrix: \n', conf_mat)


# Implementing AdaBoost
# Tuning the AdaBoost parameter 'n_estimators' and implementing cross-validation using Grid Search
model = Pipeline([
        ('balancing', SMOTE(random_state = 101)),
        ('classification', AdaBoostClassifier(random_state=1))
    ])
grid_param = {'classification__n_estimators': [2,3,4,5,10,20,30,40,50,100]}

gd_sr = GridSearchCV(estimator=model, param_grid=grid_param, scoring='accuracy', cv=5)
gd_sr.fit(X_scaled, Y)

best_parameters = gd_sr.best_params_
print(best_parameters)

best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator
print("Adaboost: ",best_result)

featimp = pd.Series(gd_sr.best_estimator_.named_steps["classification"].feature_importances_, index=list(X)).sort_values(ascending=False) # Getting feature importances list for the best model
print(featimp)

ada = AdaBoostClassifier()
ada.fit(X_train, Y_train)
y_pred = ada.predict(X_test)
conf_mat = metrics.confusion_matrix(Y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(conf_mat,annot=True)
plt.title("Confusion_matrix")
plt.xlabel("Predicted Class")
plt.ylabel("Actual class")
plt.show()
print('Confusion matrix: \n', conf_mat)



# Implementing Random Forest Classifier
# Tuning the random forest parameter 'n_estimators' and implementing cross-validation using Grid Search
model = Pipeline([
        ('balancing', SMOTE(random_state = 101)),
        ('classification', RandomForestClassifier(criterion='entropy', max_features='auto', random_state=1) )])

grid_param = {'classification__n_estimators': [10,20,30,40,50,100]}

gd_sr = GridSearchCV(estimator=model, param_grid=grid_param, scoring='accuracy', cv=5)

gd_sr.fit(X_scaled, Y)

best_parameters = gd_sr.best_params_
print(best_parameters)

best_result = gd_sr.best_score_ # Mean cross-validated score of the best_estimator
print('Random forest',best_result)

RF = RandomForestClassifier(n_estimators=400, criterion='entropy', max_features='auto', random_state=1)
RF.fit(X_train,Y_train)
prediction = RF.predict(X_test)
conf_mat = metrics.confusion_matrix(Y_test, Y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(conf_mat,annot=True)
plt.title("Confusion_matrix")
plt.xlabel("Predicted Class")
plt.ylabel("Actual class")
plt.show()
print('Confusion matrix: \n', conf_mat)


featimp = pd.Series(gd_sr.best_estimator_.named_steps["classification"].feature_importances_, index=list(X)).sort_values(ascending=False) # Getting feature importances list for the best model
print(featimp)
